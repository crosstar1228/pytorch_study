## Pytorch study tutorialğŸ§
1. pytorch_tutorial1 : torchë¡œ tensorë¥¼ ë‹¤ë£¨ëŠ” ì—¬ëŸ¬ ê¸°ì´ˆ ë°©ë²•ë¡ ì„ ê³µë¶€í•©ë‹ˆë‹¤.
2. pytorch_tutorial2 :ê¸°ë³¸ modeling, NN layer ìŒ“ê¸° ë° metric ë“± torch.nnì˜ ëª¨ë“ˆ ë° ê¸°ëŠ¥ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤.
3. pytorch_dataloader : pytorchì˜ datasetê³¼ dataloaderì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤. ê°ê° data ì „ì²˜ë¦¬, data shuffle ë° sample, collate_fn í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ í•™ìŠµì„ ìœ„í•œ ì¤€ë¹„ë¥¼ ë§ˆì¹  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.
4. pytorch_autograd : pytorchì—ì„œ gradientê°€ ì–´ë–»ê²Œ ê³„ì‚°ë˜ëŠ”ì§€, `autograd` ë©”ì†Œë“œë¥¼ í†µí•˜ì—¬ ì•Œì•„ë³´ê³   backpropagation ê³¼ì •ì„ êµ¬í˜„ì„ í†µí•´ ë³µê¸°í•´ ë´…ë‹ˆë‹¤.([ì°¸ê³ ìë£Œ](https://youtu.be/M0fX15_-xrY))

## Assignment
[week2-1](https://github.com/crosstar1228/pytorch_study/blob/main/assignment/Jesung_Ryu_Week2_1_assignment.ipynb). `bert` ëª¨ë¸ì˜ embedding vector ì¶”ì¶œ, cosine similarity ë° ìœ ì‚¬ë„
[week2-2](https://github.com/crosstar1228/pytorch_study/blob/main/assignment/Jesung_Ryu_Week2_2_assignment.ipynb). pretrained `bert`ì— hidden layerë¥¼ ìŒ“ì•„ fine-tuning, loss, optimizer, freeze/unfreeze
[week2-3](https://github.com/crosstar1228/pytorch_study/blob/main/assignment/Jesung_Ryu_Week2_3_assignment.ipynb). [Pytorch] Custom Dataset, Dataloader, collate_fn
[week2-4](https://github.com/crosstar1228/pytorch_study/blob/main/assignment/Jesung_Ryu_Week2_4_assignment.ipynb). epoch, scheduler, gradient clipping, predition& evaluation(help.py module í™œìš©)
[week3-1](https://github.com/crosstar1228/pytorch_study/blob/main/assignment/Jesung_Ryu_Week3_1_assignment_.ipynb). Dataset, Dataloader í™œìš©í•œ Word2Vec Skip-Gram Modelling
[week3-2](https://github.com/crosstar1228/pytorch_study/blob/main/assignment/Jesung_Ryu_Week3_2_assginment.ipynb). Wordpiece Tokenizer, encoding ë° decoding
[week3-4](https://github.com/crosstar1228/pytorch_study/blob/main/assignment/Jesung_Ryu_Week3_4_assginment.ipynb). Transformer ëª¨ë¸ êµ¬ì¡° ì•Œì•„ë³´ê¸°(í•„ì‚¬)